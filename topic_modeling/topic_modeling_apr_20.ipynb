{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "\n",
    "query=\"\"\"\n",
    "SELECT * FROM goldenfleece.sentiment.gkg_apr_2020_sample \n",
    "\"\"\"\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_themes(df):\n",
    "    # drop missing themes rows\n",
    "    df = df.dropna(subset=[\"V2Themes\"])\n",
    "    # split by ';' and remove everything after ',' \n",
    "    return [[re.sub(r',.*', '', theme) for theme in doc.split(';') if theme] for doc in df[\"V2Themes\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# get the processed corpus\n",
    "processed_corpus = pre_process_themes(df)\n",
    "\n",
    "# load the training dictionary\n",
    "dictionary = Dictionary.load(\"dictionary\")\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(processed_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag-of-words representation of the documents\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_corpus]\n",
    "\n",
    "# sense check first and fifth corpus\n",
    "print(f'Bag-of-words representation of the first document: {bow_corpus[0]}')\n",
    "print(f'Bag-of-words representation of the fifth document: {bow_corpus[4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "\n",
    "# load pre-trained model\n",
    "model = LdaMulticore.load(\"lda_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, bow_corpus):\n",
    "    result = {}\n",
    "    for i, row in enumerate(model[bow_corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        dominant_topic = row[0][0]\n",
    "        result[i] = dominant_topic + 1\n",
    "    return pd.Series(result, name=\"topic\")    \n",
    "\n",
    "topic = predict(model, bow_corpus)\n",
    "topic_df = df.merge(topic, left_index=True, right_index=True)\n",
    "assert len(topic) == len(topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.info(memory_usage=\"deep\")\n",
    "# topic_df[\"DATE\"] = pd.to_datetime(topic_df[\"DATE\"])\n",
    "# topic_df.to_csv(\"../data/gkg_apr_2020_sample_topic.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
